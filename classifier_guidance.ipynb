{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import DiffusionRunner\n",
    "from ddpm_sde import DDPM_SDE\n",
    "from default_mnist_config import create_default_mnist_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import ConfigDict\n",
    "import torch\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Resize,\n",
    "    Normalize,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "class ClassGuidDiffusionRunner(DiffusionRunner):\n",
    "    def __init__(self, config: ConfigDict, eval: bool = False):\n",
    "        super().__init__(config, eval)\n",
    "        self.classifier = self.get_classifier()\n",
    "        self.mnist_transforms = Compose([\n",
    "                                        Resize((config.data.image_size, config.data.image_size)),\n",
    "                                        Normalize(mean=config.data.norm_mean, std=config.data.norm_std),\n",
    "                                        ]) \n",
    "    def get_classifier(self):\n",
    "        class_model = self.config.class_guide.model\n",
    "        classifier = class_model(**self.config.class_guide.classifier_args)\n",
    "        classifier.load_state_dict(torch.load(self.config.class_guide.checkpoint_path))\n",
    "        classifier.to(self.config.device)\n",
    "        return classifier\n",
    "      \n",
    "    # def classifier_score(self, \n",
    "    #                      input_x, \n",
    "    #                      y,\n",
    "    #                      criterion=torch.nn.CrossEntropyLoss()):\n",
    "        \n",
    "    #     # target_class_index = torch.ones(input_x.shape[0]).to(self.config.device) \n",
    "    #     # target_class_index *= y \n",
    "    #     # target_class_index = target_class_index.to(self.config.device) \n",
    "    #     target_class_index =  torch.ones(input_x.shape[0]).to(self.config.device) * torch.tensor([y]).to(self.config.device)\n",
    "\n",
    "    #     input_data  = self.mnist_transforms(input_x)\n",
    "    #     input_data  = input_data.to(self.config.device)\n",
    "    #     input_data.requires_grad = True\n",
    "\n",
    "    #     output = self.classifier(input_data)\n",
    "    #     loss = criterion(output, target_class_index)\n",
    "    #     loss.backward()\n",
    "    #     gradients = input_data.grad\n",
    "    #     return gradients\n",
    "                \n",
    "    # def classifier_score(self, input_data, class_index):\n",
    "    #     self.classifier.eval()  # Убедитесь, что модель в режиме оценки (не обучения)\n",
    "\n",
    "    #     input_data.requires_grad = True  # Позволяет вычислить градиенты для входных данных\n",
    "    #     output = self.classifier(input_data)\n",
    "\n",
    "    #     # Убедитесь, что class_index соответствует одному из выходов модели\n",
    "    #     assert 0 <= class_index < output.size(1), f\"Недопустимый class_index: {class_index}\"\n",
    "\n",
    "    #     # Обнуляем градиенты перед обратным распространением ошибки\n",
    "    #     self.classifier.zero_grad()\n",
    "\n",
    "    #     # Создаем тензор с единичным значением в нужном классе\n",
    "    #     target = torch.zeros_like(output)\n",
    "    #     target[:, class_index] = 1\n",
    "\n",
    "    #     # Вычисляем функцию потерь (например, кросс-энтропию) между предсказаниями и целевыми значениями\n",
    "    #     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    #     loss = loss_fn(output, target.argmax(dim=1))\n",
    "\n",
    "    #     # Обратное распространение ошибки для вычисления градиентов входных данных\n",
    "    #     loss.backward()\n",
    "\n",
    "    #     # Получаем градиенты входных данных\n",
    "    #     gradients = input_data.grad\n",
    "\n",
    "    #     return gradients\n",
    "    \n",
    "\n",
    "    def classifier_score(self, input_data, class_index):\n",
    "        self.classifier.eval()\n",
    "        self.classifier.zero_grad()\n",
    "        with torch.enable_grad():\n",
    "            input_data.requires_grad = True\n",
    "            output = self.classifier(input_data)\n",
    "            output_for_class = output[:, class_index]\n",
    "\n",
    "            # output_for_class.backward()\n",
    "            output_for_class.backward(torch.ones_like(output_for_class))\n",
    "            gradients  = input_data.grad\n",
    "\n",
    "        return gradients\n",
    "\n",
    "\n",
    "        \n",
    "    def calc_score(self, input_x: torch.Tensor, input_t: torch.Tensor, y=None, gamma=3) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        calculate score w.r.t noisy X and t\n",
    "        input:\n",
    "            input_x - noizy image\n",
    "            input_t - time label\n",
    "        algorithm:\n",
    "            1) predict noize via DDPM\n",
    "            2) calculate std of input_x\n",
    "            3) calculate score = -pred_noize / std\n",
    "        \"\"\"\n",
    "        eps = self.model(input_x, input_t)\n",
    "        \n",
    "        std = self.sde.marginal_std(input_t)\n",
    "        std = std.view(-1, 1, 1, 1)\n",
    "        ddpm_score = -eps / std\n",
    "\n",
    "        classifier_score = self.classifier_score(input_x, y)\n",
    "\n",
    "        score = ddpm_score + gamma * classifier_score\n",
    "\n",
    "        return {\"score\" : score, \n",
    "                \"noise\" : eps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_default_mnist_config()\n",
    "runner = ClassGuidDiffusionRunner(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data  = torch.randn(2, 1, 32, 32).to(\"cuda\")\n",
    "input_data.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.5350e-02, -1.1682e-03, -1.5188e-02,  ...,  3.2827e-04,\n",
       "            3.7865e-04,  3.4775e-03],\n",
       "          [ 3.8308e-03, -6.7694e-02,  2.1623e-03,  ...,  7.1501e-03,\n",
       "           -1.5663e-02, -7.4589e-03],\n",
       "          [-1.9547e-02, -5.5258e-03, -1.0999e-02,  ..., -7.6489e-03,\n",
       "            2.3632e-03, -9.4181e-04],\n",
       "          ...,\n",
       "          [ 8.7392e-03,  2.5417e-03, -1.0556e-03,  ...,  4.7557e-03,\n",
       "            3.0294e-03, -1.4760e-02],\n",
       "          [-1.4125e-02, -9.6714e-04,  3.1654e-03,  ...,  2.8685e-03,\n",
       "           -2.1903e-02, -2.1055e-03],\n",
       "          [ 1.2173e-03,  1.2521e-02,  5.3749e-03,  ..., -8.3691e-03,\n",
       "           -3.4617e-03, -2.7530e-03]]],\n",
       "\n",
       "\n",
       "        [[[-7.8555e-03,  4.3064e-03, -1.5587e-02,  ...,  3.0190e-03,\n",
       "           -9.8673e-03,  9.0403e-04],\n",
       "          [ 1.8961e-02,  6.5144e-03, -1.8270e-03,  ...,  1.6347e-02,\n",
       "            3.5795e-02, -1.8068e-02],\n",
       "          [-3.9551e-02, -4.9772e-03, -4.6893e-02,  ..., -3.9127e-03,\n",
       "           -2.5773e-02, -8.0955e-03],\n",
       "          ...,\n",
       "          [ 1.2808e-02,  1.2637e-02, -3.2791e-03,  ..., -1.3842e-02,\n",
       "            4.8169e-03, -2.8707e-05],\n",
       "          [-7.5770e-03,  1.6400e-02,  6.8226e-03,  ...,  9.6137e-03,\n",
       "            7.8829e-03, -7.3088e-03],\n",
       "          [ 7.2891e-03,  7.6846e-04, -7.7823e-03,  ...,  4.6820e-03,\n",
       "            1.5709e-03, -2.7427e-03]]]], device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.classifier_score(input_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = runner.classifier(input_data)\n",
    "# output_for_class = output[:, 1]\n",
    "\n",
    "# # output_for_class.backward()\n",
    "# output_for_class.backward(torch.ones_like(output_for_class))\n",
    "\n",
    "# grad = input_data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones_like(output_for_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data  = torch.randn(2, 1, 32, 32).to(\"cuda\")\n",
    "t = torch.Tensor([0.1]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': tensor([[[[ 0.0075,  0.0100,  0.0043,  ..., -0.0155, -0.0097,  0.0011],\n",
       "           [ 0.0077,  0.0227, -0.0048,  ..., -0.0002,  0.0073, -0.0008],\n",
       "           [ 0.0131,  0.0001, -0.0157,  ...,  0.0150,  0.0117,  0.0131],\n",
       "           ...,\n",
       "           [ 0.0137, -0.0116, -0.0170,  ...,  0.0019,  0.0059,  0.0038],\n",
       "           [ 0.0064,  0.0042,  0.0025,  ...,  0.0089,  0.0015, -0.0007],\n",
       "           [-0.0015, -0.0036,  0.0003,  ..., -0.0141, -0.0105, -0.0048]]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'noise': tensor([[[[ 1.1030e-06, -8.0282e-07,  6.2809e-06,  ...,  6.3142e-07,\n",
       "            -3.8763e-06,  2.8395e-06],\n",
       "           [ 2.8132e-06,  6.1866e-06,  5.1360e-06,  ...,  8.7809e-06,\n",
       "            -1.8317e-07, -3.3796e-06],\n",
       "           [ 5.9697e-06,  6.8061e-06,  3.0741e-05,  ..., -5.0512e-06,\n",
       "            -2.0408e-06, -5.0607e-06],\n",
       "           ...,\n",
       "           [ 1.5850e-06,  2.7316e-06, -2.6919e-06,  ...,  1.8231e-05,\n",
       "             5.2683e-06,  6.6253e-06],\n",
       "           [-1.7719e-05, -1.1283e-05,  7.6130e-06,  ...,  1.3652e-06,\n",
       "             7.0731e-06,  4.7150e-06],\n",
       "           [-3.0526e-06, -1.9812e-05, -4.6700e-06,  ..., -1.1174e-05,\n",
       "            -6.3348e-06, -3.9249e-06]]]], device='cuda:0',\n",
       "        grad_fn=<ConvolutionBackward0>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.calc_score(input_data, t, y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import (\n",
    "    Resize,\n",
    "    Normalize,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "mnist_transforms = Compose([\n",
    "        Resize((config.data.image_size, config.data.image_size)),\n",
    "        Normalize(mean=config.data.norm_mean, std=config.data.norm_std),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "target_class_index = 2\n",
    "target_class_index = torch.tensor([target_class_index]).to(config.device) * torch.ones(2).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class_index = target_class_index.unsqueeze(-1)\n",
    "target_class_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doctor/anaconda3/envs/airi_env/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 32])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data  = torch.randn(2, 1, 32, 32)\n",
    "input_data  = mnist_transforms(input_data)\n",
    "input_data  = input_data.to(config.device)\n",
    "input_data.requires_grad = True\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = runner.classifier(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target_class_index)\n\u001b[1;32m      2\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m      3\u001b[0m gradients \u001b[39m=\u001b[39m input_data\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/anaconda3/envs/airi_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/airi_env/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/anaconda3/envs/airi_env/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target_class_index)\n",
    "loss.backward()\n",
    "gradients = input_data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_gradients(model, input_data, class_index):\n",
    "    model.eval()  # Убедитесь, что модель в режиме оценки (не обучения)\n",
    "\n",
    "    input_data.requires_grad = True  # Позволяет вычислить градиенты для входных данных\n",
    "    output = model(input_data)\n",
    "\n",
    "    # Убедитесь, что class_index соответствует одному из выходов модели\n",
    "    assert 0 <= class_index < output.size(1), f\"Недопустимый class_index: {class_index}\"\n",
    "\n",
    "    # Обнуляем градиенты перед обратным распространением ошибки\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Создаем тензор с единичным значением в нужном классе\n",
    "    target = torch.zeros_like(output)\n",
    "    target[:, class_index] = 1\n",
    "\n",
    "    # Вычисляем функцию потерь (например, кросс-энтропию) между предсказаниями и целевыми значениями\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output, target.argmax(dim=1))\n",
    "\n",
    "    # Обратное распространение ошибки для вычисления градиентов входных данных\n",
    "    loss.backward()\n",
    "\n",
    "    # Получаем градиенты входных данных\n",
    "    gradients = input_data.grad\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.1677e-03, -3.0676e-02, -3.3568e-02,  ...,  3.2892e-02,\n",
       "            1.7086e-02,  2.6695e-03],\n",
       "          [-1.9700e-02,  6.2581e-03,  1.4219e-02,  ..., -6.5805e-02,\n",
       "           -4.2931e-03,  2.2726e-02],\n",
       "          [ 1.6743e-02,  3.0358e-03,  7.6520e-03,  ..., -6.2832e-02,\n",
       "           -7.3870e-02, -4.2718e-02],\n",
       "          ...,\n",
       "          [ 1.7750e-03,  1.6841e-02,  9.7737e-04,  ...,  1.9416e-03,\n",
       "            9.2555e-03, -7.8101e-03],\n",
       "          [-6.9648e-04, -6.2951e-03,  3.3439e-03,  ...,  1.4104e-03,\n",
       "            1.4978e-03,  1.0119e-04],\n",
       "          [ 4.7081e-03,  5.0267e-03,  8.1728e-03,  ..., -3.4762e-03,\n",
       "           -5.9667e-03, -3.5863e-03]]],\n",
       "\n",
       "\n",
       "        [[[-8.3743e-03, -1.4829e-02, -1.2600e-03,  ...,  7.1794e-04,\n",
       "           -1.6119e-03, -2.0831e-03],\n",
       "          [ 4.3379e-03,  5.4015e-03, -2.7986e-02,  ..., -2.1289e-02,\n",
       "            2.0460e-03,  6.5354e-03],\n",
       "          [ 2.4116e-03, -1.7982e-02,  1.1622e-02,  ..., -3.8050e-02,\n",
       "           -4.5040e-03,  2.1441e-03],\n",
       "          ...,\n",
       "          [ 5.8457e-03,  1.5594e-02,  1.7601e-02,  ...,  1.7365e-02,\n",
       "            1.6004e-02,  9.5776e-03],\n",
       "          [ 4.3316e-03, -1.8715e-03,  1.2780e-02,  ..., -3.5851e-03,\n",
       "            5.0566e-03,  5.6065e-03],\n",
       "          [ 2.2210e-03,  1.2343e-03, -7.4547e-03,  ...,  5.6561e-03,\n",
       "            9.1097e-05,  7.9389e-03]]]], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_input_gradients(runner.classifier, input_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.0004,  0.0023, -0.0016,  ..., -0.0056, -0.0049, -0.0008],\n",
       "           [ 0.0022,  0.0023,  0.0039,  ...,  0.0033,  0.0054, -0.0027],\n",
       "           [-0.0024,  0.0026, -0.0035,  ...,  0.0038, -0.0006, -0.0044],\n",
       "           ...,\n",
       "           [-0.0022, -0.0123, -0.0042,  ..., -0.0027,  0.0029,  0.0013],\n",
       "           [-0.0057, -0.0070, -0.0078,  ..., -0.0020, -0.0015, -0.0016],\n",
       "           [-0.0004, -0.0058, -0.0045,  ..., -0.0007, -0.0012, -0.0010]]]],\n",
       "        device='cuda:0'),\n",
       " torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients, gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0, 1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3596, -2.3740, -1.6151, -1.9797, -2.3420, -1.5721, -2.7542, -2.2944,\n",
       "         -1.2308, -1.7510]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = runner.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.load_state_dict(torch.load(runner.config.class_guide.checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block': models.classifier.ResidualBlock, 'layers': [2, 2, 2, 2]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(runner.config.class_guide.classifier_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
